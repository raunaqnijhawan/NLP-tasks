{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_doc(doc):\n",
    "    f = open(doc,encoding=\"utf-8\")\n",
    "    data = f.read()\n",
    "    word_tokens = word_tokenize(data)\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    filtered_sentence = []\n",
    "    stopwords_list = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "        else:\n",
    "            stopwords_list.append(w)\n",
    "    return filtered_sentence\n",
    "def extract_q(q):\n",
    "    data = q\n",
    "    word_tokens = word_tokenize(data)\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    filtered_sentence = []\n",
    "    stopwords_list = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "        else:\n",
    "            stopwords_list.append(w)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = extract_doc(\"sixyears.txt\")\n",
    "d2 = extract_doc(\"traintonowhere.txt\")\n",
    "d3 = extract_doc(\"whatdreams.txt\")\n",
    "d4 = extract_doc(\"gettingsaucy.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         words  d1  d2  d3  d4\n",
      "0       parsed   0   1   0   0\n",
      "1      setting   0   0   1   0\n",
      "2        happy   0   0   1   0\n",
      "3        steak   0   0   0   2\n",
      "4         used   0   2   0   0\n",
      "..         ...  ..  ..  ..  ..\n",
      "895     enjoys   0   0   1   0\n",
      "896  grappling   1   0   0   0\n",
      "897    lasting   0   1   0   0\n",
      "898    growing   0   1   0   1\n",
      "899  10-minute   0   0   0   1\n",
      "\n",
      "[900 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Bag of words\n",
    "distinct_words = list(set(d1+d2+d3+d4)) \n",
    "import pandas as pd\n",
    "def Bag_of_words(word_list): \n",
    "    word_l = []\n",
    "    for word in distinct_words:\n",
    "        if (word in word_list) == True:\n",
    "            word_l.append(word_list.count(word))\n",
    "        else:\n",
    "            word_l.append(0)\n",
    "    return word_l\n",
    "df = pd.DataFrame()\n",
    "df[\"words\"] = distinct_words\n",
    "df[\"d1\"] = Bag_of_words(d1)\n",
    "df[\"d2\"] = Bag_of_words(d2)\n",
    "df[\"d3\"] = Bag_of_words(d3)\n",
    "df[\"d4\"] = Bag_of_words(d4)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         words   d1        d2   d3        d4\n",
      "0       parsed  0.0  1.000000  0.0  0.000000\n",
      "1      setting  0.0  0.000000  1.0  0.000000\n",
      "2        happy  0.0  0.000000  1.0  0.000000\n",
      "3        steak  0.0  0.000000  0.0  1.526589\n",
      "4         used  0.0  1.526589  0.0  0.000000\n",
      "..         ...  ...       ...  ...       ...\n",
      "895     enjoys  0.0  0.000000  1.0  0.000000\n",
      "896  grappling  1.0  0.000000  0.0  0.000000\n",
      "897    lasting  0.0  1.000000  0.0  0.000000\n",
      "898    growing  0.0  1.000000  0.0  1.000000\n",
      "899  10-minute  0.0  0.000000  0.0  1.000000\n",
      "\n",
      "[900 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#TF\n",
    "#We use the log function\n",
    "# tf = 1 + log(1+log(nij))\n",
    "import math\n",
    "def TF(word_list):\n",
    "    word_l = []\n",
    "    for word in distinct_words: \n",
    "        if (word in word_list) == True:\n",
    "            word_l.append(1+math.log(1+math.log(word_list.count(word))))\n",
    "        else:\n",
    "            word_l.append(0)\n",
    "    return word_l\n",
    "tf = pd.DataFrame()\n",
    "tf[\"words\"] = distinct_words\n",
    "tf[\"d1\"] = TF(d1)\n",
    "tf[\"d2\"] = TF(d2)\n",
    "tf[\"d3\"] = TF(d3)\n",
    "tf[\"d4\"] = TF(d4)\n",
    "\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word  relevance\n",
      "0       parsed   1.609438\n",
      "1      setting   1.609438\n",
      "2        happy   1.609438\n",
      "3        steak   1.609438\n",
      "4         used   1.609438\n",
      "..         ...        ...\n",
      "895     enjoys   1.609438\n",
      "896  grappling   1.609438\n",
      "897    lasting   1.609438\n",
      "898    growing   1.098612\n",
      "899  10-minute   1.609438\n",
      "\n",
      "[900 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#IDF\n",
    "idf = pd.DataFrame()\n",
    "def IDF():\n",
    "    l = []\n",
    "    D = [d1,d2,d3,d4]\n",
    "    for i in distinct_words:\n",
    "        d = 0\n",
    "        for j in D:\n",
    "            if i in j:\n",
    "                d+=1\n",
    "        l.append(math.log(1+4/d))\n",
    "    return l\n",
    " \n",
    "idf[\"word\"] = distinct_words\n",
    "idf[\"relevance\"] = IDF()\n",
    "\n",
    "print(idf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         words        d1        d2        d3        d4\n",
      "0       parsed  0.000000  1.609438  0.000000  0.000000\n",
      "1      setting  0.000000  0.000000  1.609438  0.000000\n",
      "2        happy  0.000000  0.000000  1.609438  0.000000\n",
      "3        steak  0.000000  0.000000  0.000000  2.456950\n",
      "4         used  0.000000  2.456950  0.000000  0.000000\n",
      "..         ...       ...       ...       ...       ...\n",
      "895     enjoys  0.000000  0.000000  1.609438  0.000000\n",
      "896  grappling  1.609438  0.000000  0.000000  0.000000\n",
      "897    lasting  0.000000  1.609438  0.000000  0.000000\n",
      "898    growing  0.000000  1.098612  0.000000  1.098612\n",
      "899  10-minute  0.000000  0.000000  0.000000  1.609438\n",
      "\n",
      "[900 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#TF_IDF\n",
    "import numpy as np\n",
    "tfidf = pd.DataFrame()\n",
    "tfidf[\"words\"] = distinct_words\n",
    "n1 = np.array(tf.d1)\n",
    "n2 = np.array(tf.d2)\n",
    "n3 = np.array(tf.d3)\n",
    "n4 = np.array(tf.d4)\n",
    "\n",
    "x = np.array(idf.relevance)\n",
    "tfidf[\"d1\"] = n1*x\n",
    "tfidf[\"d2\"] = n2*x\n",
    "tfidf[\"d3\"] = n3*x\n",
    "tfidf[\"d4\"] = n4*x\n",
    "\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         words        d1        d2        d3        d4\n",
      "0       parsed  0.000000  0.001788  0.000000  0.000000\n",
      "1      setting  0.000000  0.000000  0.001788  0.000000\n",
      "2        happy  0.000000  0.000000  0.001788  0.000000\n",
      "3        steak  0.000000  0.000000  0.000000  0.002730\n",
      "4         used  0.000000  0.002730  0.000000  0.000000\n",
      "..         ...       ...       ...       ...       ...\n",
      "895     enjoys  0.000000  0.000000  0.001788  0.000000\n",
      "896  grappling  0.001788  0.000000  0.000000  0.000000\n",
      "897    lasting  0.000000  0.001788  0.000000  0.000000\n",
      "898    growing  0.000000  0.001221  0.000000  0.001221\n",
      "899  10-minute  0.000000  0.000000  0.000000  0.001788\n",
      "\n",
      "[900 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#normalized TDIDF for Query and document\n",
    "tfidf.d1/=len(distinct_words)\n",
    "tfidf.d2/=len(distinct_words)\n",
    "tfidf.d3/=len(distinct_words)\n",
    "tfidf.d4/=len(distinct_words)\n",
    "print(tfidf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(d1, d2):\n",
    "  l1 = list(d1)\n",
    "  l2 = list(d2)\n",
    "  c=0\n",
    "  for i in range(len(tfidf.words)): \n",
    "          c+= l1[i]*l2[i] \n",
    "  cosine = c / float((sum(l1)*sum(l2))**0.5) \n",
    "  return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between doc 1 and doc 2 is  0.2279894819604541\n",
      "Cosine Similarity between doc 1 and doc 3 is  0.23593072757345418\n",
      "Cosine Similarity between doc 1 and doc 4 is  0.22444947517665506\n",
      "Cosine Similarity between doc 2 and doc 3 is  0.21741686092162324\n",
      "Cosine Similarity between doc 2 and doc 4 is  0.23624882983298426\n",
      "Cosine Similarity between doc 3 and doc 4 is  0.21381306271857836\n"
     ]
    }
   ],
   "source": [
    "#finding cosine similarity\n",
    "print(\"Cosine Similarity between doc 1 and doc 2 is \", cos_sim(tf.d1, tf.d2))\n",
    "print(\"Cosine Similarity between doc 1 and doc 3 is \", cos_sim(tf.d1, tf.d3))\n",
    "print(\"Cosine Similarity between doc 1 and doc 4 is \", cos_sim(tf.d1, tf.d4))\n",
    "print(\"Cosine Similarity between doc 2 and doc 3 is \", cos_sim(tf.d2, tf.d3))\n",
    "print(\"Cosine Similarity between doc 2 and doc 4 is \", cos_sim(tf.d2, tf.d4))\n",
    "print(\"Cosine Similarity between doc 3 and doc 4 is \", cos_sim(tf.d3, tf.d4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
